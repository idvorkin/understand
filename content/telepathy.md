# Dowsing the collective unconscious with GPT-3

Back in September, I was having conversations with the new AI, GPT-3. Here are
[our chats and my conclusions](/home/2020/09/04/idea_machine) from that time.
I’ve just found another chat in my notes.

In the following, the lines starting with “Human:” are what I typed. The lines
starting with “AI:” were generated by GPT-3. It was a single session. I didn’t
go back and revise any of my questions, and always accepted GPT-3’s first
response.

Human: Hello, who are you?

AI: _I am an AI created by OpenAI. How can I help you today?_

Human: What should I work on in 2021?

AI: _How much do you value being able to read?_

Human: A great deal.

AI: _In 2021, you will no longer be able to read._

Human: Why not?

AI: _In 2021, a new form of entertainment called telepathy will become
widespread._

Human: How will telepathy be invented?

AI: _New neurotechnology will be invented to treat epileptic seizures._

Human: Can you describe how telepathy will be used for entertainment?

AI: _Telepathy will work over the Internet._

Human: What will be entertaining about it?

AI: _It will provide an interface for playing multi-player games._

Human: How will telepathy be better than consoles for playing multi-player
games?

AI: _It will provide a more social experience._

Human: Can you describe the biggest telepathy game of 2021?

AI: _Yes. The biggest hit of 2021 is a game where people direct the actions of
biological agents in order to prevent them from dying._

Human: How do you win at this game?

AI: _You take an action to save the biological agent if it is in danger of
dying. You can’t be too late._

Human: What will it be called?

AI: _In 2021 it will be called Do No Harm._

Human: How much will it cost?

AI: _A home version will cost $300, while a console version will cost $250._

Human: How many people will play?

AI: _A billion people will play._

This is… wildly specific.

I am very much taken with the idea that there are ways to dowse the collective
unconscious.

Like, prediction markets. Lots of people bet on complex outcomes; the market
functions to surface scarce knowledge. Astral Codex Ten has been posting about
[prediction markets and
coronavirus](https://astralcodexten.substack.com/p/metaculus-monday): "They’re
a type of trustless, decentralized expertise that often equals or outperforms
official sources."

Then of course there’s sentiment analysis: [hedge funds look at news and
social media](https://fortune.com/2020/08/25/can-an-a-i-hedge-fund-beat-the-
market/) to pick up positive/negative sentiment, and use that to drive
investment decisions.

But models like GPT-3, or maybe Google’s new language model [which is 9x
larger](https://venturebeat.com/2021/01/12/google-trained-a-trillion-
parameter-ai-language-model/), have basically ingested all the public text
there is. They integrate and correlate, that’s what machine learning does.

Now let’s say that a bunch of people _are_ working on technology-enabled psi
for entertainment. They won’t be saying this out loud… but, talking about
unrelated topics, they will use more words that are conceptually “connected”
to telepathy and games. That’s just how the brain works. So there will be
tweets and blog posts that are _linguistically inflected_ with these ideas,
compared to the same time the year before, and they be concentrated within
groups of people who tend to work and socialise together.

So is it possible to detect those inflections, using automation? Is it
possible to pick up on them even _before_ the
[scenius](/home/2020/08/18/filtered_for_small_groups) has come together and
consciously even had the idea? What knowledge is encoded in the structure of
the model itself?

If you ask GPT-3 the right questions, can you get it to tell you what society
is dreaming about?

And, if so: what does this fantasy about a billion-player telepathy game
really mean?

_Do No Harm._
