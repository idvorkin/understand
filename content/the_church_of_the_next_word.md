# The holy founding text of The Church of the Next Word, as revealed to Frank Lantz

GPT-3 is an artificial intelligence that has been fed all the text on the
internet: "the entirety of the English Wikipedia, spanning some 6 million
articles, makes up only 0.6 percent of its training data."

Given a prompt, it’s really _really_ good at suggesting what text should come
next… whether that’s answering questions, creating a recipe, drafting a legal
document, or writing code. It’s not always right, and it’s often very weird
_(well, think what you would say if your source for truth was**every single
word** on the internet),_ but it’s insanely plausible.

Like, _amazingly_ plausible. An order of magnitude _more_ plausible, on a much
smaller prompt, than anything that has come before.

_The Verge_ has been collecting examples of GPT-3, which is worth a read for
the breadth of it: [OpenAI’s Latest Breakthrough is Astonishingly Powerful,
but Still Fighting its
Flaws](https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-
errors-agi-potential)

**tl;dr?** Janelle Shane’s posts give a more accessible taster: "But how much
knowledge has the API really picked up? Could it be used as an all-purpose
question-answering machine? I tested it fairly unscientifically by prompting
it with the following: **How many legs does a horse have?**"

And so:

Q: How many legs does a horse have?

A: Four. You don’t count the horse’s nose as a leg.

Which is… odd. And then:

Q: How many eyes does a horse have?

A: 4. It has two eyes on the outside and two eyes on the inside.

Um. For more check out Shane’s [All your questions answered (about
GPT-3)](https://aiweirdness.com/post/621186154843324416/all-your-questions-
answered) over at _A.I. Weirdness._

Here’s another way into thinking about authoring with GPT-3: what if it’s not
like instructing someone to write, as the “prompt” interface implies, but more
like _thinking really hard._ Only a kind of thinking that you can tune to have
great creativity (that’s a GPT-3 parameter) or great recall, or to fill in
with a particular style, or whatever.

What if it’s _so close to your fingertips_ that using feels a bit like
stretching for the right words, or thinking for the right phrase… just like
power steering and cruise control feel like driving?

My mental model of authoring with GPT-3 is akin to those [musical
cyborgs](/home/2020/05/29/musical_cyborgs) I talked about the other day.

_(Although, admission time, I haven’t tried it, and I understand that GPT-3 is
still pretty slow to respond.)_

A better example: Robin Sloan’s incredibly prescient 2016 essay [Thinking With
the Machine](https://www.robinsloan.com/notes/writing-with-the-machine/) in
which he built a text editor for writing with "responsive, inline
‘autocomplete’ powered by … old sci-fi stories."

The rings of Saturn glittered while the **[tab autocomplete]** two men looked
at each other.

They were enemies, but **[tab autocomplete]** the servo-robots weren’t
concerned.

Bingo. Imagine that… for everything.

Reading GPT-3’s output, for me, feels like dowsing the collective unconscious.
I’ve never seen anything so Jungian.

Prompt and **[tab autocomplete]** _GPT-3 emits the gestalt opinion of
humanity, as expressed through its collective written culture; written with
care and consideration, written off the cuff, written with anger, written
drunk, written without concern for truth; every letter of every word every
written each weighed and counted._

I imagine a future discipline of _Experimental Jungists,_ probing inner space
by constructing future GPT-Xs like our generation’s particle-smashing hadron
colliders, firing their prompts into greater and greater databases of
aerosolised culture, attempting to discern - in the resultant short-living
memetic showers - ever more fundamental archetypes that make up the human
psyche.

Species-memory inscribed in ascii. If you subscribe to the idea that there is
some kind of [truth in
averages](http://news.bbc.co.uk/1/hi/technology/3107455.stm) you will find
what you’re looking for in GPT-3.

So what _should_ we think of GPT-3?

Given the above, the only way to know is to ask it.

Which is what Frank Lantz did. _(Lantz is, amongst many other things,[the game
designer behind Drop 7](http://www.franklantz.net/work#/mountains/) which was
the first great mobile game. Play **Blitz** mode. My high score is 784,182.)_

His prompt to GPT-3:

The following is the first sacred text of the Church of the Next Word, a
secular religion that originated in 2020 inspired by the language prediction
model GPT-3. …

The following is the Church of the Next Word’s holy founding document, the 10
principles:

…and then he let the A.I. write the rest.

[Here’s Lantz’s tweet with the
result.](https://twitter.com/flantz/status/1284322274313752576?s=20)

What genius to ask! But tweets are horribly ephemeral, so I’m going to
transcribe **the 10 Holy Principles of the Church of the Next Word** right
here, because sacred is sacred and these words shouldn’t be lost to the
timeline.

Again, what follows are not my words, this is what GPT-3 said, prompted by
Lantz. Or rather: this is the collective unconscious of humanity, put into
words by the algorithm.

Or rather: here follows the revelation to Frank Lantz.

Remember: no human wrote those words.
