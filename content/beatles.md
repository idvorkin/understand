# Now and then and an infinity of extrapolated Beatles tracks

There’s a “new” track by the Beatles, grafted together from a demo by Lennon
in the 70s, guitar by Harrison in the 90s (Lennon was killed in 1980. Harrison
died in 2001), and new strings and drums from McCartney and Starr.

Plus a lot of production, using AI.

That demo from Lennon: "The very original recording is just John playing the
piano with TV in the background" – that’s Giles Martin, producer, son of
George Martin.

Other tracks layered on similar poor recordings resulted in Lennon’s voice
sounding “ghostly.” That was 1994.

So this time they used technology developed for Peter Jackson’s _Get Back_
documentary on Disney+ (which is incredible btw).

“Essentially, what the machine learning does is it recognizes someone’s voice.
So if you and I have a conversation and we’re in a crowded room and there’s a
piano playing in the background, we can teach the AI what the sound of your
voice, the sound of my voice, and it can extract those voices,” Martin said.

Listen to the new track here: [The Beatles - Now And Then (Official
Audio)](https://www.youtube.com/watch?v=AW55J2zE3N4) _(YouTube)._

It’s… pretty good?

Like, musically, it’s ok. I find the strings arrangement a little too much
maybe? McCartney’s taste has been so era-defining that, weirdly, his work
starts to sound generic. (I say this as a McCartney fan! Read [64 Reasons To
Celebrate Paul McCartney](https://www.ian-leslie.com/p/64-reasons-to-
celebrate-paul-mccartney) and be convinced.)

But it’s a lot and to my ear, it’s too smooth.

Because what really shines is Lennon’s voice. My goodness have they done a
good job with that. They should have given it more room.

Mechanically recovered from the slurry of old tape recordings or not, 50%
reconstruction or not, Lennon’s voice shines through time and up through the
muddy waters of AI algorithms. It is poignant and beautiful to hear him sing.
Familiar and unfamiliar all at once.

Mind you I’m in Liam Gallagher’s camp given [what he said in The
Guardian](https://www.theguardian.com/music/2023/nov/02/now-and-then-listen-
to-the-final-beatles-song-john-lennon-paul-mccartney-ringo-george-harrison):
"The Beatles could shit in my handbag and I’d still hide my polo mints in
there."

ASIDE:

Here’s a _Wild Palms_ reference seeing as [I’m a massive
fan](/home/2021/10/18/genre) and even from 1993 they pinpointed this modern
era before any of us:

Episode 4, after lounge singer Chap Starfall has been murdered by the Friends,
the Senator et al have a hologram of him playing as background music. He was
their buddy.

Tabba Schwartzkopf is watching: "Hate to say it but I like him so much better
since he died. That posthumous quality really makes me shiver."

Look – _Wild Palms_ nailed both the nature of the technology S-curve and the
effect of VR/the metaverse/synthetic reality/fake news/whatever you want to
call it, _all as background colour,_ wrapped up in a melodrama about LA media
through the eyes of a patent attorney. I will never miss an opportunity to
evangelise.

I’m trying to figure out how I feel about _Now and Then._

Is there any legitimate difference - poignancy aside - between this AI
extrapolation and, well, me never having heard a track before?

I have an ANALOGY.

_Dummy_ by Portishead – released in 1994.

A contender for the best album of my lifetime. A haunting trip-hop soundtrack
over 30 years.

I copied it onto tape for my car. Later ripped the CD into iTunes, listened
endlessly there.

Portishead’s third album _Three_ came out in 2008. In terms of which group has
a better three album oeuvre: there is none.

I was never a Spotify listener. But Apple Music shipped in 2015, and at some
point the streaming edition of the album shouldered out my ripped version,
and:

There was a new track.

I can’t even discover when [It’s a Fire](https://youtu.be/selAvZE6lp4)
_(YouTube)_ appeared. It’s not on the U.K. original release.

It’s probably my favourite track now because each time I hear it, it still
feels brand new. Imagine your favourite album for two decades suddenly has an
extra song! It’s wild.

So my control experiment is right here. Music spear-fishes both kinds of
memory - emotional and episodic - and reliably hauls up exotic and forgotten
species from the deep past. And _It’s a Fire_ has none of that for me. No gang
of mates smoking in a front room. No silhouetted dark woods out of the car
window in the witching hour. No bar, no working in a cafe, no running up
Parliament Hill on Hampstead Heath at sun-up, no residual sense recall of the
feel of the cracked plastic compact disk case packed and unpacked with my uni
belongings. Simply: the music.

AND YET, even without all of that, I love it.

Here’s my conclusion:

Yes there is some (large) component of the _“unit”_ of music/art/etc which is
its subjective significance. But it turns out that this isn’t essential. The
work can stand alone.

How about authenticity?

Does _Now and Then_ lose something because Lennon wasn’t in the room?

Can I _hear_ inauthenticity? I suspect not. I can hear the pre-2020s
_consequences_ of inauthenticity: a song without authenticity sounds empty.

But here in the 20s that has changed. We can say that _Now and Then_ is a
patchwork construction (but isn’t all studio-produced music) and macabre
certainly (but as Schwartzkopf said, doesn’t it make you shiver?) - but it
isn’t hollow. It’s not low quality.

So authenticity doesn’t matter either.

We’ve seen AI-extrapolated art before ([as previously
discussed](/home/2020/12/02/extrapolation)) and it just hasn’t been very
_good._ Like, it’s novel but it lacks something, and my preconception has been
that there was no _way_ that AI art can be good because it doesn’t have the
original human touch, or the provenance (societal or personal).

But what I believe now is that it’s do with the effectiveness of the machine.

_AI art will be good._ We will one day have new Van Goghs, new Beatles tracks,
new episodes of Firefly, and so long as they’re good - which they will be - my
prediction is that we won’t mind where they come from. Quality will overcome
it all. Caring about the origins will be nerdy like specifying which show
runner you preferred on _The West Wing._

So we should lean into extrapolated art maybe?

And that would be an easy thing to do?

Simon Willison recently did a deep dive into OpenAI’s new image synthesis AI:
[Now add a walrus: Prompt engineering in DALL-E
3](https://simonwillison.net/2023/Oct/26/add-a-walrus/).

The random number seed caught my attention. Simon

Simon: "I’m pretty stunned by this."

It’s a surprising result! My mental model of AI image synthesis has been that
(a) yes images look great, but (b) they’re pretty chaotic. i.e. a change in
the prompt, even an extra bit of punctuation, will send the AI spiralling off
in a different direction and the resultant image will look very different.

What this deep dive shows that is that variance in the results is down to a
random number generator. That’s what the “seed” is: it’s a number to feed into
the image synthesis. The seed is randomly generated – but now I need to update
my mental model to state that the image synthesis _itself_ is actually
deterministic.

_(I’ve tried to reproduce Simon’s experiment but ChatGPT will not tell me the
seed for DALL-E-generated images. So I think that hole has been closed.)_

The consequences of there being a seed:

It makes AI synthesis way more reproducible. That means you can sit there
tweaking and tuning a prompt and narrowing in on something intentional – this
makes AI much less of a novelty, and much more like the creative process. It
will reward work and skill.

It also reminds me that the words of the prompt become numbers too: vector
embeddings, which can be mathematically combined.

As AI imagery, so AI music.

Now John Lennon probably isn’t a 10 digit integer. The seed isn’t
deterministic like that. But passable Lennon probably _is_ a 1,024 dimensional
vector in embedding space.

And given that, there’s not just _Now and Then_ but an infinity of possible
extrapolated Beatles tracks.

We’d have to figure out the ethics and the IP (both fascinating rabbit holes
in their own right) but perhaps we should lean into that, instead of pre-
emptively blocking the possibility in the UI, which is what happens now,
because who knows what would happen next.
