# Multiplayer docs, webcam fashion, noisy icons: three ideas

Let’s say I wake up one morning and I’m magically in charge of Android, iOS,
or Mac OS. What do I do? **Here are three ideas aimed at making operating
systems more social.**

It _matters_ what goes in operating systems. Almost 20 years ago, many of us
were banging the drum for location-aware computing. It’s hard to imagine now
that computers (by which I include phones) _didn’t know where they were._ But
put location in the OS, and you enable everything from turn-by-turn
directions, to advertising, to takeaways, to Tinder.

ASIDE: If you’re into the history, [Know Your
Place](https://www.researchgate.net/publication/318802531_FCJ-216_%27Know_Your_Place%27_headmap_manifesto_and_the_Vision_of_Locative_Media)
(July 2017, The Fibreculture Journal) is an examination of the visionary and
influential _headmap manifesto_ for “locative media” (as it was called) by Ben
Russell from 1999.

_Another example:_

[Fonts on the original
Macintosh](https://en.wikipedia.org/wiki/Fonts_on_Macintosh#Fonts_of_the_original_Macintosh),
1984, which was early in using fonts with "characters of different widths,
often referred to as proportional fonts." (Previously most computers were more
like typewriters.) The story goes that Steve Jobs went to a calligraphy class
at college, and ended up caring a ton about typography. And so we ended up
with desktop publishing and the democratisation of design!

**Laptops and smartphones never escaped their PC history.** They’re still
_personal_ computers, all our socialising and collaborating channeled through
individual apps like email and Facebook. To be natively social, we need social
capabilities at the OS level.

So, let me join the dots on a few recent blog posts, and briefly lay out some
starting points…

Google Docs is amazing (and Sheets, and Slides). Like, _of course_ in docs you
should be able to

After all, this is exactly what you’d in a meeting room with a whiteboard, or
in a cafe scribbling on a napkin.

Then you get the unintended uses of those capabilities like [spreadsheet
parties, as previously discussed](/home/2020/06/15/hallway_track).

Figma, the online design tool, [has has multiplayer mode since
2016](https://www.figma.com/blog/multiplayer-editing-in-figma/). A designer
can show their work to viewers, all their cursors swarming round. More
unintended uses: [Tom Critchlow has been using Figma for
salons.](https://tomcritchlow.com/2020/07/16/salons/)

And then there’s the new generation of collaboration apps such as
[MakeSpace](https://makespace.fun) with its video selfie cursors and shared
canvas.

I find it insane that Google never turned Google Docs into a framework for all
web apps.

Live text editing, multiplayer cursors, comments and chat: these are powerful
primitives. Why doesn’t every text editor on the web, every sketching app, and
every music maker include this? Google could have enabled that.

It’s not too late.

If I were Apple, or Google with Android, I’d bake this into the OS. It should
be a native feature of the operating system, just like menu, or the file save
dialog box.

Every application window should be thought of as a _room._ Tap on a window,
open the door, and see cursors swarm, text get edited, and comments stream in.
(Different cursors for different windows, naturally.)

**And one of those team members? An artificial intelligence assistant.** I
talked yesterday about how [the ideal interface to AIs is the
team](/home/2020/11/19/ai_collaboration)

Erving Goffman, sociologist, his 1956 book [The Presentation of Self in
Everyday
Life](https://en.wikipedia.org/wiki/The_Presentation_of_Self_in_Everyday_Life):

when an individual comes in contact with other people, that individual will
attempt to control or guide the impression that others might make of him by
changing or fixing his or her setting, appearance, and manner.

Like… of course?

Goffman focuses on politeness: "all participants in social interactions are
engaged in practices to avoid being embarrassed or embarrassing others."

And _costume:_ "the dress and look of the performer."

Agency in self-presentation is about as close as you can get to a human
fundamental. Sure enough, there are filters in individual apps. Yet there’s
barely any attention given, at the OS level, to this kind of “dressing up,” to
costume.

[I wrote in October about virtual fashion](/home/2020/10/21/virtual_fashion):
"How about skin tight t-shirts with tracking markers, especially made for
rendering synthetic shirts with physics-model fabric for wearing on Zoom?"

And there are glimpses of apps that play in this domain. Recently I saw
[xpression camera on Product
Hunt](https://www.producthunt.com/posts/xpression-camera). It intercepts your
webcam and lets you change your appearance on any call. Like, you give it an
image of a person, and then it deepfakes your face into the image. Check out
the second photo on that Product Hunt page: "Take a photo of yourself in a
suit, so you can attend Zoom meetings in your pyjamas."

The ability to not brush my hair for video calls is ABSOLUTELY a worthy
operating system-level feature.

Is this trivial? I imagine people said the Mac’s focus on typography was a
triviality when it launched in the 80s. But creative expression is what humans
are all about, and nice fonts ([and ugly
fonts…](/home/2012/05/22/ze_frank_on_ugly)) tap directly into that.

Here’s another: the video/podcast-editing tool _Descript._ [Check out their
launch video on YouTube.](https://www.youtube.com/watch?v=Bl9wqNe5J8U) At 1
minute 50, you’ll see the ability to scrub every _uh_ and _um_ from your
voice, automatically.

This is no different from spellcheck. We have spellcheck because it’s
important to be _professional._ But computers (I include phones in this) are
subject to the tyranny of work. What about hanging out with my friends? I want
to sound cool and look silly, or whatever.

So for my second act, I’d bake deepfakes, dressing up, and yes, **an app store
for virtual fashion** right into the OS. Give presentation-of-self features an
absolute _ton_ of attention.

Notifications are a system-level feature. Good.

But notifications are a blunt instrument.

Long-time listeners will know of my interest in [social peripheral
vision](/home/2015/10/08/tomtown), the idea that you should be able to sense,
as if from the corner of your eye, the busyness of a Slack channel, or the
fact that a friend is slowly and quietly posting gorgeous photos somewhere.

And from that gentle, non-urgent awareness, you can build up (or not) to full
focus.

But how should it work? One thought…

There’s an idea buried in [my post about video calling
interop](/home/2020/10/14/protocols) from a few weeks back:

The icons on my home screen should appear “noisy” somehow if they’re currently
full of my friends. Getting notifications only when I’m direct-mentioned is
such a crude mechanism: I want to know where the action is!

**Noisy icons.** What if each icon gave off ripples? _But the ripples would be
static._ If they did animate, it would be very slow.

From a visual scan of your home screen, you’d see which apps were busy and
which were quiet. Bigger ripples if more of your friends are active; bigger
ripples if your name is mentioned. Each app could have its own volume control.

Imagine seeing ripples around the Google Docs app as if there were some deep,
distant activity. Open it… and there’s a particular document humming with
comments. You listen at the door, you can tell who’s active, and the frequency
of the interactions, but not what they’re saying precisely… a ping as your
name is mentioned (the notification of which wouldn’t have bubbled all the way
up to your home screen as it’s not important enough, but since you’re here) -
so you enter and join your colleagues.

It’s not going to happen, nobody’s going to give me the keys to designing the
OS.

But I’d love to see social computing given the attention that it deserves. As
you can tell, I’m frustrated that OS designers and engineers haven’t gone
further down this path already.

Just as, in the days of locative media, in 1999 before smartphones and before
consumer GPS, we could only guess at what would happen with location-based
computings, I feel like we’ve only scratched the surface with social, and I
want to see what apps and services would be newly-enabled and newly-imagined
by system-level Lego bricks like these.
