# Post at 10.27, on Friday 4 Feb 2011

Here are some [Japanese fighting robots on
television](http://digitalcortex.net/technology/there-should-be-more-robots-
on-tv/ "Lots of little robots.") (remote controlled; two arms and two legs
each). My favourite is the one with the balloon for the head and his special
move.

(I found that via this essay [On the Potential for Branded
Robots,](http://digitalcortex.net/work/opinion/on-the-potential-for-branded-
robots/ "Big question!") which is a big question! I wonder about the ethics.
Robots don't have sentient feelings (yet), so it's fine to treat them as
slaves. But they _appear_ to be sentient, and humans interact with them _as
if_ they are sentient. So what does it do to us as people, if we accustom
ourselves to not having to care about other sentient beings? Is that okay?
Might we start treating the non-robot sentiences around us callously too --
the human working in the train station, the human making us coffee, the human
in the call-centre, the cat we meet on the street? Should we, for our own
sakes, make robots tender and fragile so that we don't accidentally train
ourselves into being heartless?)
